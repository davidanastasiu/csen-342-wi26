{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 10-2: The Pre-trained Giant – \"Fine-Tuning BERT\"\n",
    "\n",
    "**Course:** CSEN 342: Deep Learning  \n",
    "**Topic:** Transformers, BERT, Tokenization, and Transfer Learning\n",
    "\n",
    "## Objective\n",
    "In the lecture, we learned about **BERT** (Bidirectional Encoder Representations from Transformers). BERT changed the NLP landscape by providing a pre-trained \"language understanding\" engine that can be fine-tuned for almost any text task.\n",
    "\n",
    "In this tutorial, we will:\n",
    "\n",
    "1.  **Understand Tokenization:** See how BERT breaks words into \"subwords\" to handle unknown vocabulary.\n",
    "2.  **Fine-Tune DistilBERT:** Adapt a pre-trained model to classify news articles (AG News dataset).\n",
    "3.  **Perform Inference:** Build a pipeline to classify your own text.\n",
    "\n",
    "We will use **DistilBERT**, a smaller, faster, cheaper version of BERT that retains 97% of its performance.\n",
    "\n",
    "**NOTE**: Run this notebook under the `Transformers Bundle` kernel rather than the class kernel.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Robust Setup (The Offline Cache)\n",
    "\n",
    "Compute nodes often block Python libraries from opening connections, but allow system tools like `wget`. We will manually download the model components and the dataset into a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.6.0+cu118\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp39-cp39-linux_x86_64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: torchvision in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (4.57.6)\n",
      "Requirement already satisfied: accelerate in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from torch==2.6.0+cu118) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from torch==2.6.0+cu118) (4.12.2)\n",
      "Requirement already satisfied: networkx in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from torch==2.6.0+cu118) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from torch==2.6.0+cu118) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from torch==2.6.0+cu118) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m199.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m150.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m199.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m181.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m210.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.2.0 (from torch==2.6.0+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.6.0+cu118)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from sympy==1.13.1->torch==2.6.0+cu118) (1.3.0)\n",
      "Requirement already satisfied: numpy in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from torchvision) (2.0.2)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp39-cp39-linux_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from torchvision) (11.3.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp39-cp39-linux_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from transformers) (0.36.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: requests in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from jinja2->torch==2.6.0+cu118) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /WAVE/apps2/el8/conda/envs/JupyterHub/20240824-CUDA/lib/python3.9/site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp39-cp39-linux_x86_64.whl (848.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp39-cp39-linux_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.4.0\n",
      "    Uninstalling triton-3.4.0:\n",
      "      Successfully uninstalled triton-3.4.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages/~riton'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.8.0\n",
      "    Uninstalling torch-2.8.0:\n",
      "      Successfully uninstalled torch-2.8.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages/~orch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.23.0\n",
      "    Uninstalling torchvision-0.23.0:\n",
      "      Successfully uninstalled torchvision-0.23.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages/~orchvision.libs'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/WAVE/users2/unix/danastasiu/.local/lib/python3.9/site-packages/~orchvision'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.8.0\n",
      "    Uninstalling torchaudio-2.8.0:\n",
      "      Successfully uninstalled torchaudio-2.8.0\n",
      "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 sympy-1.13.1 torch-2.6.0+cu118 torchaudio-2.6.0+cu118 torchvision-0.21.0+cu118 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "# Run if needed...\n",
    "!python -m pip install --user torch==2.6.0+cu118 torchvision torchaudio transformers accelerate --index-url https://download.pytorch.org/whl/cu118\n",
    "# Restart the kernel after installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files ready.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_root = '../data'\n",
    "model_root = '../data/distilbert_local'\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "os.makedirs(model_root, exist_ok=True)\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        print(f\"Downloading {os.path.basename(save_path)}...\")\n",
    "        # -nc: No clobber, -q: Quiet (except errors), -O: Output file\n",
    "        exit_code = os.system(f\"wget -nc -q -O {save_path} {url}\")\n",
    "        if exit_code != 0:\n",
    "            print(f\"Error downloading {url}\")\n",
    "\n",
    "# 1. Download AG News Dataset\n",
    "dataset_url = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\"\n",
    "dataset_path = os.path.join(data_root, 'ag_news_train.csv')\n",
    "download_file(dataset_url, dataset_path)\n",
    "\n",
    "# 2. Download DistilBERT Model Files (Hugging Face Hub)\n",
    "# We need these specific files to load the model \"offline\"\n",
    "base_hf_url = \"https://huggingface.co/distilbert-base-uncased/resolve/main/\"\n",
    "files_to_fetch = [\n",
    "    \"config.json\",\n",
    "    \"pytorch_model.bin\",\n",
    "    \"vocab.txt\",\n",
    "    \"tokenizer.json\",\n",
    "    \"tokenizer_config.json\"\n",
    "]\n",
    "\n",
    "for filename in files_to_fetch:\n",
    "    download_file(base_hf_url + filename, os.path.join(model_root, filename))\n",
    "\n",
    "print(\"All files ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Tokenizer\n",
    "\n",
    "Transformers don't read words; they read **Tokens**. \n",
    "BERT uses **WordPiece** tokenization. It breaks common words into wholes (`apple`) and rare words into chunks (`app`, `##le`). This solves the \"Unknown Word\" problem.\n",
    "\n",
    "We load the tokenizer from our local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Transformers are fascinating!\n",
      "Tokens:   ['[CLS]', 'transformers', 'are', 'fascinating', '!', '[SEP]']\n",
      "IDs:      tensor([  101, 19081,  2024, 17160,   999,   102])\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Load from local path\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_root)\n",
    "\n",
    "# Demonstration\n",
    "text = \"Transformers are fascinating!\"\n",
    "encoded = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "print(f\"Original: {text}\")\n",
    "print(f\"Tokens:   {tokenizer.convert_ids_to_tokens(encoded['input_ids'][0])}\")\n",
    "print(f\"IDs:      {encoded['input_ids'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "* `[CLS]`: Special classification token added to the start. The model uses the embedding of this token to represent the *entire sentence*.\n",
    "* `[SEP]`: Separator token at the end.\n",
    "* `##ing`: The \"##\" indicates this token is attached to the previous one.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Dataset Class\n",
    "\n",
    "We wrap the AG News CSV. \n",
    "\n",
    "**Classes:** 1-World, 2-Sports, 3-Business, 4-Sci/Tech. (We will map them to 0-3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AGNewsDataset(Dataset):\n",
    "    def __init__(self, csv_path, tokenizer, max_len=64, samples=2000):\n",
    "        # Load only a subset for tutorial speed\n",
    "        self.df = pd.read_csv(csv_path, header=None).sample(n=samples, random_state=42)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Columns: 0=Class, 1=Title, 2=Description\n",
    "        text = str(row[1]) + \" \" + str(row[2]) \n",
    "        label = int(row[0]) - 1 # Convert 1-4 to 0-3\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create Loaders\n",
    "dataset = AGNewsDataset(dataset_path, tokenizer)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The Model & Fine-Tuning\n",
    "\n",
    "We use `DistilBertForSequenceClassification`. This class wraps the raw DistilBERT model and adds a simple Linear Layer on top of the `[CLS]` token output.\n",
    "\n",
    "**Fine-Tuning:** We update *all* weights (BERT + Head), but with a small learning rate ($2e-5$ is standard for BERT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ../data/distilbert_local and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fine-Tuning (this might take 2-3 mins on GPU)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 0.7517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load Model from local path\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_root, \n",
    "    num_labels=4 # 4 classes in AG News\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epochs=1):\n",
    "    print(\"Starting Fine-Tuning (this might take 2-3 mins on GPU)...\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # HF models return a tuple (loss, logits)\n",
    "            outputs = model(input_ids, attention_mask=mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}: Loss {avg_loss:.4f}\")\n",
    "\n",
    "train(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Inference\n",
    "\n",
    "Let's test the model on new, unseen sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Predictions ---\n",
      "Text: The stock market crashed today after the new inflation report.\n",
      "Pred: Business\n",
      "\n",
      "Text: Manchester United scored a late goal to win the championship.\n",
      "Pred: Sports\n",
      "\n",
      "Text: Apple released a new iPhone with a faster processor.\n",
      "Pred: Sci/Tech\n",
      "\n",
      "Text: Peace talks in the middle east have stalled again.\n",
      "Pred: World\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "\n",
    "def predict(text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=64, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "        \n",
    "    return class_names[prediction]\n",
    "\n",
    "# Test Cases\n",
    "samples = [\n",
    "    \"The stock market crashed today after the new inflation report.\",\n",
    "    \"Manchester United scored a late goal to win the championship.\",\n",
    "    \"Apple released a new iPhone with a faster processor.\",\n",
    "    \"Peace talks in the middle east have stalled again.\"\n",
    "]\n",
    "\n",
    "print(\"--- Predictions ---\")\n",
    "for s in samples:\n",
    "    pred = predict(s)\n",
    "    print(f\"Text: {s}\")\n",
    "    print(f\"Pred: {pred}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "You have successfully fine-tuned a Transformer!\n",
    "\n",
    "**Why this works:**\n",
    "The pre-trained BERT model already \"knows\" English grammar, syntax, and some world knowledge (from reading Wikipedia). Fine-tuning simply teaches it how to map that understanding to your 4 specific categories.\n",
    "\n",
    "**In the next tutorial:** We will look at *Generative* Transformers (GPT) which can write text instead of just classifying it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformers Bundle",
   "language": "python",
   "name": "transformers-bundle-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
